{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Enable importing pysparky\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/17 11:19:18 WARN Utils: Your hostname, codespaces-0aafae resolves to a loopback address: 127.0.0.1; using 10.0.10.147 instead (on interface eth0)\n",
      "24/10/17 11:19:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/17 11:19:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pysparky import functions as F_\n",
    "from pysparky import spark_ext as se\n",
    "from pysparky import transformations as te\n",
    "from pysparky import utils\n",
    "\n",
    "print(pyspark.__version__)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysparky import functions as F_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\"id\": [1, 2, 3], \"value1\": [10, 20, 30]}\n",
    "data2 = {\"id\": [1, 2, 4], \"value2\": [100, 200, 400]}\n",
    "data3 = {\"id\": [1, 3, 5], \"value3\": [1000, 3000, 5000]}\n",
    "\n",
    "df1 = spark.createDataFrame_from_dict(data1)\n",
    "df2 = spark.createDataFrame_from_dict(data2)\n",
    "df3 = spark.createDataFrame_from_dict(data3)\n",
    "\n",
    "dataframes = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = utils.join_dataframes_on_column(\"id\", *dataframes, how=\"left\")\n",
    "result_data = result_df.collect()\n",
    "\n",
    "expected_data = [\n",
    "    (1, 10, 100, 1000),\n",
    "    (2, 20, 200, None),\n",
    "    (3, 30, None, 3000),\n",
    "]\n",
    "\n",
    "expected_df = spark.createDataFrame(expected_data, [\"id\", \"value1\", \"value2\", \"value3\"])\n",
    "expected_result = expected_df.collect()\n",
    "\n",
    "assert sorted(result_data) == sorted(expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n",
      "| id|value1|value2|value3|\n",
      "+---+------+------+------+\n",
      "|  1|    10|   100|  1000|\n",
      "|  2|    20|   200|  NULL|\n",
      "|  3|    30|  NULL|  3000|\n",
      "+---+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n",
      "| id|value1|value2|value3|\n",
      "+---+------+------+------+\n",
      "|  1|    10|   100|  1000|\n",
      "|  3|    30|  NULL|  3000|\n",
      "|  2|    20|   200|  NULL|\n",
      "+---+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
