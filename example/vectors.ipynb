{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e63cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/01 14:49:42 WARN Utils: Your hostname, TCEU3048M.local resolves to a loopback address: 127.0.0.1; using 192.168.151.110 instead (on interface en0)\n",
      "25/07/01 14:49:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/01 14:49:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Enable importing pysparky\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame, Column\n",
    "from pyspark.sql import functions as F, types as T\n",
    "\n",
    "print(pyspark.__version__)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46648bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /Users/cenz.wong/pysparky-pyspark-helper/.venv/lib/python3.13/site-packages (80.9.0)\n",
      "Requirement already satisfied: numpy in /Users/cenz.wong/pysparky-pyspark-helper/.venv/lib/python3.13/site-packages (2.3.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cenz.wong/pysparky-pyspark-helper/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cenz.wong/pysparky-pyspark-helper/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2af3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- v1: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- vec1: vector (nullable = true)\n",
      "\n",
      "+------+---------+\n",
      "|    v1|     vec1|\n",
      "+------+---------+\n",
      "|[1, 3]|[1.0,3.0]|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.functions import array_to_vector\n",
    "\n",
    "df1 = spark.createDataFrame(\n",
    "    [\n",
    "        ([1.5, 2.5],),\n",
    "    ],\n",
    "    schema=\"v1 array<double>\",\n",
    ")\n",
    "df1.select(array_to_vector(\"v1\").alias(\"vec1\")).collect()\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [\n",
    "        ([1.5, 3.5],),\n",
    "    ],\n",
    "    schema=\"v1 array<float>\",\n",
    ")\n",
    "df2.select(array_to_vector(\"v1\").alias(\"vec1\")).collect()\n",
    "\n",
    "df3 = spark.createDataFrame(\n",
    "    [\n",
    "        ([1, 3],),\n",
    "    ],\n",
    "    schema=\"v1 array<int>\",\n",
    ")\n",
    "df3.select(\"v1\", array_to_vector(\"v1\").alias(\"vec1\")).printSchema()\n",
    "df3.select(\"v1\", array_to_vector(\"v1\").alias(\"vec1\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c98fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
